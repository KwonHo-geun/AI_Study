{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KwonHo-geun/AI_Study/blob/main/25.07.15_DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 DenseNet: Densely Connected Convolutional Networks\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ DenseNet이란?\n",
        "\n",
        "**DenseNet**은 2017년 CVPR에서 발표된 구조로,  \n",
        "기존 CNN의 정보 손실 문제와 gradient vanishing 문제를 해결하기 위해 등장했습니다.\n",
        "\n",
        "> 핵심 아이디어:  \n",
        "> **모든 이전 레이어의 출력을 다음 레이어 입력으로 연결**한다는 것\n",
        "\n",
        "DenseNet은 각 레이어가 **앞선 모든 레이어의 feature map을 입력으로 받아**,  \n",
        "feature를 재사용(reuse)하고 gradient 흐름을 개선합니다."
      ],
      "metadata": {
        "id": "MG-MswPRt5Dj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔍 DenseNet의 구조 핵심: Dense Block\n",
        "\n",
        "일반 CNN은 레이어들이 순차적으로 연결됩니다:\n",
        "\n",
        "```\n",
        "x₀ → x₁ → x₂ → x₃ → ...\n",
        "```\n",
        "\n",
        "DenseNet에서는 다음과 같이 연결됩니다:"
      ],
      "metadata": {
        "id": "kqP_38DMuPo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "x₁ = H₁(x₀)  \n",
        "x₂ = H₂([x₀, x₁])  \n",
        "x₃ = H₃([x₀, x₁, x₂])  \n",
        "...\n",
        "```\n",
        "\n",
        "- `[x₀, x₁, ..., x_{l-1}]`: 채널 방향으로 concat한 것\n",
        "- `Hₗ`: 각 레이어의 연산 (BN → ReLU → Conv)\n",
        "\n",
        "모든 이전 출력이 다음 입력에 **concatenation**되어 전달되는 것이 핵심입니다."
      ],
      "metadata": {
        "id": "Bg-S1aaGuQfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧱 Dense Block 구조\n",
        "\n",
        "```\n",
        "Input\n",
        " ├── Layer 1: H₁(x₀)\n",
        " ├── Layer 2: H₂([x₀, x₁])\n",
        " ├── Layer 3: H₃([x₀, x₁, x₂])\n",
        " └── ...\n",
        " ↓\n",
        "Transition Layer (1×1 Conv + AvgPool)\n",
        "```\n",
        "\n",
        "- 여러 개의 레이어가 하나의 블록을 구성\n",
        "- 블록 사이에는 Transition Layer를 통해 크기 및 채널 수 조절"
      ],
      "metadata": {
        "id": "V4sijmR0uRA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***요약 ***\n",
        "- 정보의 재사용으로 메모리와 파라미터를 효율적으로 사용가능  \n",
        "- Bottleneck : 병목현상 줄임\n",
        "- Feature 크기 : 채널 수 줄임\n",
        "- Feature를 더이상 학습하지 않고, 마지막 층에있는 것들만 계산한다는것\n",
        "- 즉, 각각의 Conv2 layer들은 바뀌지 않고, 별도의 채널로 두고 Transition Layer로 조정\n",
        "\n",
        "- concat(=concatenate)\n",
        "주어진 차원을 따라 텐서들을 연결하는데 사용\n",
        "딥 러닝에서는 주로 모델의 입력 또는 중간 연산에서 두 개의 텐서를 연결하는 경우가 많음.\n",
        "두 텐서를 연결해서 입력으로 사용하는 것은 두 가지의 정보를 모두 사용한다는 의미."
      ],
      "metadata": {
        "id": "U6dZJmjzt7oN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚙️ 주요 구성 요소\n",
        "\n",
        "### 1. Dense Block\n",
        "- BN → ReLU → 1×1 Conv (Bottleneck)\n",
        "- BN → ReLU → 3×3 Conv\n",
        "- 결과를 입력과 함께 concat\n",
        "\n",
        "### 2. Transition Layer\n",
        "- 1×1 Conv + 2×2 AvgPooling\n",
        "- feature map의 크기와 채널 수를 줄임\n",
        "\n",
        "### 3. Growth Rate (k)\n",
        "- 각 레이어가 생성하는 채널 수\n",
        "- DenseNet-121 기준: `k = 32`\n"
      ],
      "metadata": {
        "id": "RtLmHWNfum55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🚀 DenseNet의 장점\n",
        "\n",
        "| 장점 | 설명 |\n",
        "|------|------|\n",
        "| ✅ Feature reuse | 이전 feature를 concat하여 재사용 |\n",
        "| ✅ 효율적 파라미터 | 깊은 구조 대비 적은 파라미터 |\n",
        "| ✅ Gradient 흐름 개선 | Dense connection으로 역전파 경로가 풍부 |\n",
        "| ✅ Regularization 효과 | dropout 없이도 과적합 방지 효과 |\n"
      ],
      "metadata": {
        "id": "lsOFLSIbunak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📊 일반 CNN vs DenseNet\n",
        "\n",
        "| 항목 | 일반 CNN | DenseNet |\n",
        "|------|-----------|----------|\n",
        "| 연결 방식 | 순차 연결 | 모든 이전 레이어와 연결 |\n",
        "| 정보 재사용 | 없음 | 활발히 재사용 |\n",
        "| 파라미터 수 | 비교적 많음 | 적음 |\n",
        "| Gradient 흐름 | 제한적 | 매우 활발 |\n",
        "\n",
        "---\n",
        "\n",
        "## 🧬 DenseNet-121 예시 구조\n",
        "\n",
        "- Conv1: 7×7 Conv + MaxPool\n",
        "- Dense Block 1 (6 layers)\n",
        "- Transition Layer\n",
        "- Dense Block 2 (12 layers)\n",
        "- Transition Layer\n",
        "- Dense Block 3 (24 layers)\n",
        "- Transition Layer\n",
        "- Dense Block 4 (16 layers)\n",
        "- Global Avg Pool\n",
        "- FC Layer\n",
        "\n",
        "총 121개의 레이어로 구성됨\n",
        "\n",
        "## 🧪 PyTorch 예제\n",
        "\n",
        "```python\n",
        "from torchvision.models import densenet121\n",
        "\n",
        "model = densenet121(pretrained=True)\n",
        "print(model)\n",
        "```\n",
        "\n",
        "- torchvision에는 `densenet121`, `densenet161`, `densenet169`, `densenet201`이 포함되어 있음\n",
        "- Feature extractor 또는 fine-tuning용으로 널리 활용됨\n",
        "\n",
        "---\n",
        "\n",
        "## 📚 참고 자료\n",
        "\n",
        "- 논문: [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)\n",
        "- PyTorch Docs: https://pytorch.org/vision/stable/models/generated/torchvision.models.densenet121.html\n"
      ],
      "metadata": {
        "id": "fTROVWBQutGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 다운로드\n",
        "\n",
        "!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "id": "bTpB_RAC5kO2",
        "outputId": "87c6ed3b-a6b4-405d-bd86-6213be2b6d5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-16 11:02:23--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.181.207, 142.250.125.207, 209.85.200.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.181.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘cats_and_dogs_filtered.zip’\n",
            "\n",
            "cats_and_dogs_filte 100%[===================>]  65.43M   217MB/s    in 0.3s    \n",
            "\n",
            "2025-07-16 11:02:23 (217 MB/s) - ‘cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "if os.path.exists('/content/cats_and_dogs_filtered/'):    # 작업 디렉토리는 cats_and_dogs_filtered\n",
        "\n",
        "    shutil.rmtree('/content/cats_and_dogs_filtered/')\n",
        "    print('/content/cats_and_dogs_filtered/  is removed !!!')"
      ],
      "metadata": {
        "id": "78f2jp4O5pR3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 압축파일 풀기\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/cats_and_dogs_filtered.zip', 'r') as target_file:\n",
        "\n",
        "    target_file.extractall('/content/')"
      ],
      "metadata": {
        "id": "XJ1OZQCX5rAz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# train data 개수\n",
        "\n",
        "train_cats_list = os.listdir('/content/cats_and_dogs_filtered/train/cats/')\n",
        "\n",
        "train_dogs_list = os.listdir('/content/cats_and_dogs_filtered/train/dogs/')\n",
        "\n",
        "# validation data 개수\n",
        "\n",
        "test_cats_list = os.listdir('/content/cats_and_dogs_filtered/validation/cats/')\n",
        "\n",
        "test_dogs_list = os.listdir('/content/cats_and_dogs_filtered/validation/dogs/')\n",
        "\n",
        "print(len(train_cats_list), len(train_dogs_list))\n",
        "\n",
        "print(len(test_cats_list), len(test_dogs_list))"
      ],
      "metadata": {
        "id": "pjFwAiUO5tqt",
        "outputId": "268fb4ae-5410-4b58-c216-6143e8b34fd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 1000\n",
            "500 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, models, transforms\n"
      ],
      "metadata": {
        "id": "cJdmHUTxubgI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddir = '/content/cats_and_dogs_filtered'\n",
        "\n",
        "batch_size = 4\n",
        "num_workers = 2\n",
        "\n",
        "data_transformers = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n",
        "    ])\n",
        "}\n",
        "\n",
        "img_data = {\n",
        "    'train': datasets.ImageFolder(\n",
        "        os.path.join(ddir, 'train'),\n",
        "        data_transformers['train']\n",
        "    ),\n",
        "    'val': datasets.ImageFolder(\n",
        "        os.path.join(ddir, 'validation'),\n",
        "        data_transformers['val']\n",
        "    )\n",
        "}\n",
        "\n",
        "dloaders = {\n",
        "    k: torch.utils.data.DataLoader(\n",
        "        img_data[k], batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        "    )\n",
        "    for k in ['train', 'val']\n",
        "}\n",
        "dset_sizes = {x: len(img_data[x]) for x in ['train', 'val']}\n",
        "classes = img_data['train'].classes\n",
        "dvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "ixKhakmZ4LhJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate):\n",
        "        super().__init__()\n",
        "\n",
        "        inner_channel = 4 * growth_rate\n",
        "\n",
        "        self.bottle_neck = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, inner_channel, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(inner_channel),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(inner_channel, growth_rate, kernel_size=3, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([x, self.bottle_neck(x)], 1)\n",
        "\n",
        "\n",
        "class Transition(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.down_sample = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.AvgPool2d(2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down_sample(x)\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_class=100):\n",
        "        super().__init__()\n",
        "        self.growth_rate = growth_rate\n",
        "\n",
        "        inner_channels = 2 * growth_rate\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, inner_channels, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.features = nn.Sequential()\n",
        "\n",
        "        for index in range(len(nblocks) - 1):\n",
        "            self.features.add_module(\"dense_block_layer_{}\".format(index), self._make_dense_layers(block, inner_channels, nblocks[index]))\n",
        "            inner_channels += growth_rate * nblocks[index]\n",
        "\n",
        "            out_channels = int(reduction * inner_channels) # int() will automatic floor the value\n",
        "            self.features.add_module(\"transition_layer_{}\".format(index), Transition(inner_channels, out_channels))\n",
        "            inner_channels = out_channels\n",
        "\n",
        "        self.features.add_module(\"dense_block{}\".format(len(nblocks) - 1), self._make_dense_layers(block, inner_channels, nblocks[len(nblocks)-1]))\n",
        "        inner_channels += growth_rate * nblocks[len(nblocks) - 1]\n",
        "        self.features.add_module('bn', nn.BatchNorm2d(inner_channels))\n",
        "        self.features.add_module('relu', nn.ReLU(inplace=True))\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.linear = nn.Linear(inner_channels, num_class)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.features(output)\n",
        "        output = self.avgpool(output)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.linear(output)\n",
        "        return output\n",
        "\n",
        "    def _make_dense_layers(self, block, in_channels, nblocks):\n",
        "        dense_block = nn.Sequential()\n",
        "        for index in range(nblocks):\n",
        "            dense_block.add_module('bottle_neck_layer_{}'.format(index), block(in_channels, self.growth_rate))\n",
        "            in_channels += self.growth_rate\n",
        "        return dense_block\n",
        "\n",
        "\n",
        "def densenet121(num_class=100):\n",
        "    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=32, num_class=num_class)\n"
      ],
      "metadata": {
        "id": "QsitlRWsub5D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loss_func, optimizer, epochs=10):\n",
        "    start = time.time()\n",
        "\n",
        "    accuracy = 0.0\n",
        "\n",
        "    for e in range(epochs):\n",
        "        print(f'Epoch number {e}/{epochs - 1}')\n",
        "        print('=' * 20)\n",
        "\n",
        "        # for each epoch we run through the training and validation set\n",
        "        for dset in ['train', 'val']:\n",
        "            if dset == 'train':\n",
        "                model.train()  # set model to train mode (i.e. trainbale weights)\n",
        "            else:\n",
        "                model.eval()   # set model to validation mode\n",
        "\n",
        "            loss = 0.0\n",
        "            successes = 0\n",
        "\n",
        "            # iterate over the (training/validation) data.\n",
        "            for imgs, tgts in dloaders[dset]:\n",
        "                imgs = imgs.to(dvc)\n",
        "                tgts = tgts.to(dvc)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(dset == 'train'):\n",
        "                    ops = model(imgs)\n",
        "                    _, preds = torch.max(ops, 1)\n",
        "                    loss_curr = loss_func(ops, tgts)\n",
        "                    # backward pass only if in training mode\n",
        "                    if dset == 'train':\n",
        "                        loss_curr.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                loss += loss_curr.item() * imgs.size(0)\n",
        "                successes += torch.sum(preds == tgts.data)\n",
        "\n",
        "            loss_epoch = loss / dset_sizes[dset]\n",
        "            accuracy_epoch = successes.double() / dset_sizes[dset]\n",
        "\n",
        "            print(f'{dset} loss in this epoch: {loss_epoch}, accuracy in this epoch: {accuracy_epoch}')\n",
        "            if dset == 'val' and accuracy_epoch > accuracy:\n",
        "                accuracy = accuracy_epoch\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_delta = time.time() - start\n",
        "    print(f'Training finished in {time_delta // 60}mins {time_delta % 60}secs')\n",
        "    print(f'Best validation set accuracy: {accuracy}')\n",
        "\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "7qqvt2bIt3Rx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = densenet121(2)\n",
        "if torch.cuda.is_available() :\n",
        "  model = model.cuda()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "tHTIFNeBwjMu",
        "outputId": "cc9392b7-389e-423f-8713-5fcf97c27752",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DenseNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (features): Sequential(\n",
            "    (dense_block_layer_0): Sequential(\n",
            "      (bottle_neck_layer_0): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_1): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_2): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_3): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_4): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_5): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transition_layer_0): Transition(\n",
            "      (down_sample): Sequential(\n",
            "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "    )\n",
            "    (dense_block_layer_1): Sequential(\n",
            "      (bottle_neck_layer_0): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_1): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_2): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_3): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_4): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_5): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_6): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_7): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_8): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_9): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_10): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_11): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transition_layer_1): Transition(\n",
            "      (down_sample): Sequential(\n",
            "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "    )\n",
            "    (dense_block_layer_2): Sequential(\n",
            "      (bottle_neck_layer_0): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_1): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_2): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_3): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_4): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_5): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_6): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_7): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_8): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_9): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_10): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_11): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_12): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_13): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_14): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_15): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_16): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_17): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_18): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_19): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_20): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_21): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_22): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_23): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transition_layer_2): Transition(\n",
            "      (down_sample): Sequential(\n",
            "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "    )\n",
            "    (dense_block3): Sequential(\n",
            "      (bottle_neck_layer_0): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_1): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_2): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_3): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_4): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_5): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_6): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_7): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_8): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_9): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_10): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_11): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_12): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_13): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_14): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (bottle_neck_layer_15): Bottleneck(\n",
            "        (bottle_neck): Sequential(\n",
            "          (0): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (4): ReLU(inplace=True)\n",
            "          (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (linear): Linear(in_features=1024, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "pretrained_model = train(model, loss_func, optimizer, epochs=5)"
      ],
      "metadata": {
        "id": "4p6z4LU3wksy",
        "outputId": "eac41f0f-c2bd-4a49-8af7-e4d591d11dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number 0/4\n",
            "====================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-1170430350.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpretrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3-47108790.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_func, optimizer, epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# backward pass only if in training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                         \u001b[0mloss_curr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colab 시작하기",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}