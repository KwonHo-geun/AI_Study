{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KwonHo-geun/AI_Study/blob/main/25_07_16_MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📱 MobileNet 시리즈 : V1, V2, V3\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ MobileNet 개요\n",
        "\n",
        "MobileNet은 Google이 2017년부터 개발한 **경량화 합성곱 신경망 (CNN)** 아키텍처입니다.  \n",
        "주요 목적은 다음과 같습니다:\n",
        "\n",
        "- **모바일 및 임베디드 장치에서도 실시간 추론이 가능하도록 설계**\n",
        "- **적은 연산량(MACs), 작은 모델 크기, 낮은 지연시간(Latency)**을 달성\n",
        "- 하지만 정확도도 일정 수준 이상 유지\n",
        "\n",
        "> MobileNet은 V1 → V2 → V3로 발전하면서, 점점 더 높은 정확도와 효율성을 달성했습니다.\n"
      ],
      "metadata": {
        "id": "BoGQBPGD6wf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 MobileNetV1 (2017)\n",
        "\n",
        "### ✨ 핵심 아이디어: **Depthwise Separable Convolution**\n",
        "\n",
        "일반적인 Convolution은 **공간 필터링 + 채널 혼합**을 한 번에 수행하지만,  \n",
        "MobileNetV1은 이 과정을 **둘로 분리**합니다.\n",
        "\n",
        "#### ✅ Depthwise Separable Convolution이란?\n",
        "\n",
        "> 기존 Conv 연산을 아래 두 단계로 나눈 것:\n",
        "\n",
        "1. **Depthwise Convolution**\n",
        "   - 각 입력 채널마다 하나의 필터를 적용 (공간적 필터링만 수행)\n",
        "2. **Pointwise Convolution (1x1 Conv)**\n",
        "   - 모든 채널을 조합하여 정보 통합 (채널 간 연산)\n",
        "\n",
        "#### ✅ 연산량 감소 효과\n",
        "\n",
        "- 일반 Conv 연산량: `Dk×Dk×M×N×H×W`\n",
        "- Depthwise Separable Conv: `Dk×Dk×M×H×W + M×N×H×W`\n",
        "- 연산량 약 **8~9배 감소**, 정확도 손실은 크지 않음\n",
        "\n",
        "### 🔍 구조 예시"
      ],
      "metadata": {
        "id": "y92BETo66weA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📈 성능 향상 요소\n",
        "\n",
        "- V1 대비 파라미터 수는 비슷하지만, **정확도 대폭 향상**\n",
        "- MobileNetV2는 EfficientNet, YOLOv4 등의 **백본(backbone)**으로도 활용됨\n",
        "\n",
        "---\n",
        "\n",
        "## 🔹 MobileNetV3 (2019)\n",
        "\n",
        "### ✨ 목적: \"최고의 효율을 자동으로 찾자!\"\n",
        "\n",
        "MobileNetV3는 **NAS(Neural Architecture Search)** 기반으로 설계되었으며,  \n",
        "구조는 V2를 기반으로 하되, 다양한 **최적화 요소**가 포함되었습니다.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 주요 구성 요소\n",
        "\n",
        "| 구성 요소 | 설명 |\n",
        "|-----------|------|\n",
        "| ✅ NAS 기반 구조 설계 | Google AutoML로 블록 구조 자동 탐색 |\n",
        "| ✅ Squeeze-and-Excitation(SE) | 채널 간 중요한 특징을 강조 |\n",
        "| ✅ h-swish Activation | swish 함수의 경량 근사 버전 |\n",
        "| ✅ 다양한 block 조합 | stage마다 적절한 layer 수를 자동 탐색 |\n",
        "| ✅ 두 가지 모델 제공 | MobileNetV3-Large / MobileNetV3-Small |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kpq05XSi6wcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📊 MobileNet 시리즈 비교 요약\n",
        "\n",
        "| 항목 | MobileNetV1 | MobileNetV2 | MobileNetV3 |\n",
        "|------|-------------|-------------|-------------|\n",
        "| 주요 기술 | Depthwise Separable Conv | Inverted Residual + Linear Bottleneck | NAS + SE + h-swish |\n",
        "| 연산 효율 | 매우 높음 | 높음 | 최고 수준 |\n",
        "| 정확도 | 낮음 | 개선됨 | 가장 우수 |\n",
        "| 활용도 | 모바일 앱 | 실시간 추론 백본 | SOTA 모델, EfficientNet-Lite 등 |\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 실전 활용 예시\n",
        "\n",
        "- TensorFlow Lite / ONNX로 변환 후 모바일 앱에 탑재\n",
        "- Raspberry Pi + OpenCV 기반 실시간 영상 분석\n",
        "- YOLOv4-Tiny, BlazeFace 등 경량 Object Detection의 backbone\n",
        "\n",
        "---\n",
        "\n",
        "## 📚 참고 자료\n",
        "\n",
        "- [MobileNetV1 Paper (2017)](https://arxiv.org/abs/1704.04861)\n",
        "- [MobileNetV2 Paper (2018)](https://arxiv.org/abs/1801.04381)\n",
        "- [MobileNetV3 Paper (2019)](https://arxiv.org/abs/1905.02244)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "tjxxDucE6waP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "z6_J6nlH7AwO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MobileNet V2\n",
        "\n",
        "https://arxiv.org/abs/1801.04381\n",
        "\n",
        "https://pytorch.org/vision/0.12/_modules/torchvision/models/mobilenetv2.html#mobilenet_v2"
      ],
      "metadata": {
        "id": "4T-OuuSC6wYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models.mobilenet_v2()"
      ],
      "metadata": {
        "id": "6XBdlw8u7FSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MobileNet V3\n",
        "\n",
        "https://arxiv.org/abs/1905.02244\n",
        "\n",
        "\n",
        "https://pytorch.org/vision/0.12/models.html#mobilenet-v3\n"
      ],
      "metadata": {
        "id": "FMKt3uHN6wV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v3_large = models.mobilenet_v3_large()\n",
        "mobilenet_v3_small = models.mobilenet_v3_small()\n",
        "mobilenet_v3_small"
      ],
      "metadata": {
        "id": "5jBfOugr7Jd_",
        "outputId": "056ce2c1-bb51-4266-f8a5-a7c57608f1a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV3(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "      (2): Hardswish()\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
              "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
              "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
              "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (scale_activation): Hardsigmoid()\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (12): Conv2dNormActivation(\n",
              "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "      (2): Hardswish()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
              "    (1): Hardswish()\n",
              "    (2): Dropout(p=0.2, inplace=True)\n",
              "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colab 시작하기",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}